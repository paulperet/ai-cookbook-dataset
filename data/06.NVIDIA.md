# Guide: Using Phi-3-Vision with NVIDIA NIM for Image Processing

This guide walks you through using the **Phi-3-Vision** model via **NVIDIA NIM** to generate and execute Python code for image processing tasks. NVIDIA NIM provides optimized microservices for deploying generative AI models with standard APIs.

## Prerequisites

Before starting, ensure you have:
- An NVIDIA API key (sign up at [NVIDIA NGC](https://catalog.ngc.nvidia.com/))
- Python 3.8+
- An image file named `demo.png` in an `./imgs/` directory

## Step 1: Setup Environment

Install the required Python package:

```bash
pip install langchain_nvidia_ai_endpoints -U
```

## Step 2: Import Libraries

Import the necessary modules:

```python
from langchain_nvidia_ai_endpoints import ChatNVIDIA
import getpass
import os
import base64
```

## Step 3: Configure API Key

Set your NVIDIA API key as an environment variable:

```python
if not os.getenv("NVIDIA_API_KEY"):
    os.environ["NVIDIA_API_KEY"] = getpass.getpass("Enter your NVIDIA API key: ")
```

This securely prompts for your key if it's not already set.

## Step 4: Initialize the Model

Specify the Phi-3-Vision model and create a chat instance:

```python
model = 'microsoft/phi-3-vision-128k-instruct'
chat = ChatNVIDIA(model=model)
```

## Step 5: Prepare the Image

Define the image path and encode it as a base64 string:

```python
img_path = './imgs/demo.png'

with open(img_path, "rb") as f:
    image_b64 = base64.b64encode(f.read()).decode()
image = f'<img src="data:image/png;base64,{image_b64}" />'
```

This encoding allows the model to process the image data within the prompt.

## Step 6: Create the Prompt

Combine your instruction with the encoded image:

```python
text = "Please create Python code for image, and use plt to save the new picture under imgs/ and name it phi-3-vision.jpg."
prompt = f"{text} {image}"
```

The prompt instructs the model to generate Python code that processes the image and saves a new version.

## Step 7: Generate Code with the Model

Stream the response from the model to collect the generated code:

```python
code = ""
for chunk in chat.stream(prompt):
    print(chunk.content, end="")
    code += chunk.content
```

The model returns the response in chunks, which we concatenate into a single string.

## Step 8: Extract the Python Code

The model's response typically includes markdown code blocks. Extract just the Python code:

```python
begin = code.index('```python') + 9
code = code[begin:]
end = code.index('```')
code = code[:end]
```

This removes the surrounding markdown syntax.

## Step 9: Execute the Generated Code

Run the extracted Python code using a subprocess:

```python
import subprocess
result = subprocess.run(["python", "-c", code], capture_output=True)
```

This executes the generated code, which should process the image and save it as `./imgs/phi-3-vision.jpg`.

## Step 10: Display the Results

Finally, display both the original and processed images to verify the output:

```python
from IPython.display import Image, display
display(Image(filename='./imgs/phi-3-vision.jpg'))
display(Image(filename='./imgs/demo.png'))
```

## Summary

You've successfully used NVIDIA NIM with the Phi-3-Vision model to:
1. Send an image and processing instruction to the model
2. Receive generated Python code tailored to your request
3. Execute that code to process the image
4. View the results

This workflow demonstrates how AI can automate code generation for specific tasks, accelerating development processes.