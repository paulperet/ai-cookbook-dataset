# Implementing Question Answering with Weaviate and OpenAI

This guide walks you through setting up a vector database with Weaviate, populating it with data, and performing question-answering using OpenAI's models. You'll learn how to leverage Weaviate's integrated modules to handle vectorization and Q&A without manual embedding.

## Prerequisites

Before starting, ensure you have:
- An OpenAI API key
- A running Weaviate instance (cloud or local)
- Python 3.7+

## Setup

Install the required Python libraries:

```bash
pip install weaviate-client>3.11.0 datasets apache-beam
```

Set your OpenAI API key as an environment variable:

```bash
export OPENAI_APIKEY="your-openai-api-key-here"
```

Verify the key is set correctly in your Python environment:

```python
import os

if os.getenv("OPENAI_APIKEY") is not None:
    print("OPENAI_APIKEY is ready")
else:
    print("OPENAI_APIKEY environment variable not found")
```

## Step 1: Connect to Weaviate

Establish a connection to your Weaviate instance. Replace the URL and API key with your own values.

```python
import weaviate
import os

client = weaviate.Client(
    url="https://your-wcs-instance-name.weaviate.network/",  # WCS URL
    # url="http://localhost:8080/",  # Local instance URL
    auth_client_secret=weaviate.auth.AuthApiKey(api_key="<YOUR-WEAVIATE-API-KEY>"),  # Optional: only if using authentication
    additional_headers={
        "X-OpenAI-Api-Key": os.getenv("OPENAI_APIKEY")  # Pass OpenAI key
    }
)

# Verify connection
print("Client ready:", client.is_ready())
```

## Step 2: Define the Data Schema

Create a schema that defines your data structure and configures the OpenAI modules. This tells Weaviate which properties to vectorize and which Q&A model to use.

```python
# Clear any existing schema
client.schema.delete_all()

# Define Article class schema
article_schema = {
    "class": "Article",
    "description": "A collection of articles",
    "vectorizer": "text2vec-openai",  # Use OpenAI for embeddings
    "moduleConfig": {
        "text2vec-openai": {
            "model": "text-embedding-3-small",  # Embedding model
            "type": "text"
        },
        "qna-openai": {
            "model": "gpt-3.5-turbo-instruct",  # Q&A model
            "maxTokens": 16,
            "temperature": 0.0,
            "topP": 1,
            "frequencyPenalty": 0.0,
            "presencePenalty": 0.0
        }
    },
    "properties": [
        {
            "name": "title",
            "description": "Title of the article",
            "dataType": ["string"]
        },
        {
            "name": "content",
            "description": "Contents of the article",
            "dataType": ["text"]
        },
        {
            "name": "url",
            "description": "URL to the article",
            "dataType": ["string"],
            "moduleConfig": {
                "text2vec-openai": {
                    "skip": True  # Don't vectorize URLs
                }
            }
        }
    ]
}

# Create the schema
client.schema.create_class(article_schema)

# Verify schema creation
print("Schema created:", client.schema.get())
```

## Step 3: Import Data

Load a sample dataset and import it into Weaviate. The `text2vec-openai` module will automatically generate embeddings during import.

```python
from datasets import load_dataset

# Load Simple Wikipedia dataset
dataset = list(load_dataset("wikipedia", "20220301.simple")["train"])

# Use a subset for demonstration (adjust based on your needs)
dataset = dataset[:2500]  # 2.5k articles for testing

# Configure batch import for efficiency
client.batch.configure(
    batch_size=10,
    dynamic=True,  # Adjust batch size dynamically
    timeout_retries=3
)

# Import data
print("Importing Articles...")
counter = 0

with client.batch as batch:
    for article in dataset:
        if counter % 10 == 0:
            print(f"Imported {counter}/{len(dataset)} articles")
        
        properties = {
            "title": article["title"],
            "content": article["text"],
            "url": article["url"]
        }
        
        batch.add_data_object(properties, "Article")
        counter += 1

print("Import complete!")

# Verify import
result = client.query.aggregate("Article").with_fields("meta { count }").do()
print("Total objects imported:", result["data"]["Aggregate"]["Article"][0]["meta"]["count"])
```

## Step 4: Create a Q&A Function

Define a helper function to query your data using Weaviate's Q&A module. This function sends questions to the indexed content and returns answers generated by OpenAI.

```python
def qna(query, collection_name="Article"):
    """
    Perform question answering on the specified collection.
    
    Args:
        query: The question to answer
        collection_name: Name of the Weaviate class to query
    
    Returns:
        List of results with answers and metadata
    """
    properties = [
        "title", "content", "url",
        "_additional { answer { hasAnswer property result startPosition endPosition } distance }"
    ]

    ask = {
        "question": query,
        "properties": ["content"]  # Search within content property
    }

    result = (
        client.query
        .get(collection_name, properties)
        .with_ask(ask)
        .with_limit(1)  # Get top result
        .do()
    )
    
    # Error handling
    if "errors" in result:
        print("Error: You may have exceeded OpenAI API rate limits (60 calls/minute)")
        raise Exception(result["errors"][0]['message'])
    
    return result["data"]["Get"][collection_name]
```

## Step 5: Run Queries

Test your Q&A system with sample questions. The function returns answers along with relevance scores.

```python
# Example query 1
query_result = qna("Did Alanis Morissette win a Grammy?")

for i, article in enumerate(query_result):
    answer = article['_additional']['answer']
    if answer['hasAnswer']:
        print(f"{i+1}. Answer: {answer['result']}")
        print(f"   Relevance distance: {round(article['_additional']['distance'], 3)}")
        print(f"   Source: {article['title']}")
    else:
        print("No answer found in the retrieved context")

# Example query 2
query_result = qna("What is the capital of China?")

for i, article in enumerate(query_result):
    answer = article['_additional']['answer']
    if answer['hasAnswer']:
        print(f"{i+1}. Answer: {answer['result']}")
        print(f"   Relevance distance: {round(article['_additional']['distance'], 3)}")
    else:
        print("No specific answer found in the retrieved context")
```

## How It Works

1. **Automatic Vectorization**: When you import data, Weaviate's `text2vec-openai` module calls OpenAI's embedding API to convert text into vectors.
2. **Efficient Indexing**: Weaviate creates a vector index for fast similarity searches.
3. **Integrated Q&A**: The `qna-openai` module:
   - Retrieves relevant context based on vector similarity
   - Sends the context and question to OpenAI's completions endpoint
   - Returns generated answers with source references

## Next Steps

- Experiment with different OpenAI models in the schema configuration
- Adjust the `maxTokens` and `temperature` parameters for varied answer styles
- Implement multi-hop questioning by chaining queries
- Add filtering to constrain searches to specific topics or date ranges

You've now built a complete question-answering system using Weaviate and OpenAI. The integration handles all vector operations automatically, allowing you to focus on querying and application logic.