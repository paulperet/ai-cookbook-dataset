# Multi-Spectral Remote Sensing with Gemini: A Cookbook Guide

Learn how to leverage Gemini's multimodal capabilities for zero-shot analysis of satellite imagery by incorporating multi-spectral data. This guide demonstrates a technique to transform specialized spectral band information into a format Gemini can understand, enabling accurate remote sensing tasks without model fine-tuning.

## Prerequisites & Setup

### 1. Install the Required SDK

Begin by installing the Google Generative AI Python SDK.

```bash
pip install -U -q "google-genai>=1.0.0"
```

### 2. Configure Your API Key

Set up your Gemini API key. This example assumes the key is stored in a Colab Secret named `GEMINI_API_KEY`. For other environments, you can load the key from an environment variable or a configuration file.

```python
from google.colab import userdata
from google import genai

GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')
client = genai.Client(api_key=GEMINI_API_KEY)
```

### 3. Select a Model

For this tutorial, we'll use the `gemini-3-flash-preview` model. You can experiment with other models from the Gemini family.

```python
MODEL_ID = "gemini-3-flash-preview"
```

### 4. Import Helper Libraries

Import the necessary libraries for handling images and data.

```python
from IPython.display import display, Markdown, Image
import numpy as np
import matplotlib.pyplot as plt
```

---

## Part 1: The Challenge of RGB-Only Satellite Imagery

First, let's test Gemini's ability to interpret a standard RGB satellite image. We'll use an image of a forest captured by the Sentinel-2 satellite.

### Step 1: Download the RGB Image

```python
!wget -q https://storage.googleapis.com/generativeai-downloads/gemini-cookbook/images/remote-sensing/forest.png -O forest.png
```

### Step 2: Prompt Gemini for Classification

We'll ask Gemini to classify the image into one of several land-use categories.

```python
prompt = """
Classify this image as one of the following categories:
AnnualCrop, Forest, HerbaceousVegetation, Highway, Industrial, Pasture, PermanentCrop, Residential, River, SeaLake.
"""
```

### Step 3: Generate a Response

Send the image and prompt to the Gemini model.

```python
from google.genai import types

with open('forest.png', 'rb') as f:
  image_bytes = f.read()

response = client.models.generate_content(
    model=MODEL_ID,
    contents=[
        types.Part.from_bytes(
        data=image_bytes,
        mime_type='image/png',
        ),
        prompt
        ]
    )

print(response.text)
```

**Output:**
```
Based on the visual information provided, the image is best classified as **SeaLake**.
```

**Analysis:** The model incorrectly classifies the forest as a `SeaLake`. This error occurs because the model is interpreting the blue/green hues in the standard RGB image as water. It lacks the critical multi-spectral data (like Near-Infrared) that would clearly indicate healthy vegetation.

---

## Part 2: Enhancing Accuracy with Multi-Spectral Data

To perform zero-shot multi-spectral analysis, we need to:
1.  Transform multi-spectral inputs into a pseudo-visual space (images).
2.  Provide a prompt that scientifically describes what these new images represent.

### Step 1: Download Multi-Spectral Composite Images

We'll download five additional images derived from different combinations of Sentinel-2's spectral bands.

```bash
!wget -q https://storage.googleapis.com/generativeai-downloads/gemini-cookbook/images/remote-sensing/forest_0.jpeg -O forest_0.jpeg
!wget -q https://storage.googleapis.com/generativeai-downloads/gemini-cookbook/images/remote-sensing/forest_1.jpeg -O forest_1.jpeg
!wget -q https://storage.googleapis.com/generativeai-downloads/gemini-cookbook/images/remote-sensing/forest_2.jpeg -O forest_2.jpeg
!wget -q https://storage.googleapis.com/generativeai-downloads/gemini-cookbook/images/remote-sensing/forest_3.jpeg -O forest_3.jpeg
!wget -q https://storage.googleapis.com/generativeai-downloads/gemini-cookbook/images/remote-sensing/forest_4.jpeg -O forest_4.jpeg
!wget -q https://storage.googleapis.com/generativeai-downloads/gemini-cookbook/images/remote-sensing/forest_5.jpeg -O forest_5.jpeg
```
*   `forest_0.jpeg` is the original RGB image.
*   Images 1-5 represent different band combinations (e.g., False Color Composite, NDVI) that reveal features invisible in RGB.

### Step 2: Construct a Domain-Specific Prompt

The prompt must explain the scientific meaning behind each composite image to guide Gemini's interpretation.

```python
multispectral_prompt = """
Instructions: Answer the question asked after the given 6 images of the same scene.
The images are generated by selecting different bands of the Sentinel-2 satellite.
The band information is as follows:
1. B02: Blue band at 10-meter resolution
2. B03: Green band at 10-meter resolution
3. B04: Red band at 10-meter resolution
4. B05: Red edge band (Central wavelength of 704.1 nm) at 20-meter resolution
5. B06: Red edge band (Central wavelength of 740.5 nm) at 20-meter resolution
6. B07: Red edge band (Central wavelength of 782.8 nm) at 20-meter resolution
7. B08: NIR band at 10-meter resolution
8. B8A: Narrow NIR band at 20-meter resolution
9. B01: Costal Aerosol band at 60-meter resolution
10. B09: Water vapor band at 60-meter resolution
11. B11: SWIR band (Central wavelength 1613.7 nm) at 20-meter resolution
12. B12: SWIR band (Central wavelength 2202.4 nm) at 20-meter resolution.
The first image is the RGB image generated using B04, B03 and B02 bands.
The second image is the False Color Composite image generated using B08, B04 and B03 bands.
The third image is the NDVI image which is a colormap with values Red, Yellow and Green
generated using B08 and B04 bands.
The fourth image is NDWI image whose values are in the range of -0.8 to 0.8 and using
a color map varying linearly as [(1, 1, 1), (1, 1, 1), (0, 0, 1)].
The fifth and sixth images are the NDMI images generated using B8A and B11 or B12 bands
with the colormap varying linearly as [(1, 0, 0), (0, 1, 0), (0, 0, 1)].
Output format: Output the option numbers corresponding to the correct answer in the format
"(X)" where X is the correct number choice. In case of multiple correct
answers, output the answer choices in the same format separated by commas. For example,
if the correct answers are choices 1 and 3, output "(1),(3)". Only output the option
numbers in the above format and DO NOT OUTPUT the full answer text or any other extra words.
Question: To which of the following classes do the given images belong to? Select all that apply. Possible answer choices:
(1) AnnualCrop, (2) Forest, (3) HerbaceousVegetation, (4) Highway, (5) Industrial, (6) Pasture, (7) PermanentCrop, (8) Residential, (9) River, (10) SeaLake.
"""
```

### Step 3: Upload Images and Generate a Response

Upload the images using the Files API and send them along with the detailed prompt to Gemini.

```python
# Upload each image file
image_0 = client.files.upload(file="forest_0.jpeg")
image_1 = client.files.upload(file="forest_1.jpeg")
image_2 = client.files.upload(file="forest_2.jpeg")
image_3 = client.files.upload(file="forest_3.jpeg")
image_4 = client.files.upload(file="forest_4.jpeg")
image_5 = client.files.upload(file="forest_5.jpeg")

# Generate content with all images and the prompt
response = client.models.generate_content(
    model=MODEL_ID,
    contents=[image_0, image_1, image_2, image_3, image_4, image_5, multispectral_prompt])

print(response.text)
```

**Output:**
```
(2)
```

**Result:** The model now correctly outputs `(2)`, which corresponds to **Forest**. By providing the multi-spectral composites and the domain knowledge prompt, Gemini can accurately classify the satellite scene.

---

## Part 3: Creating Your Own Multi-Spectral Composite Images

Now, let's learn how to create these informative composite images from raw spectral band data. The process involves:
1.  Selecting spectral bands relevant to your problem.
2.  Scaling the band data to a 0-255 range and mapping it to RGB channels to create a viewable image.

### Step 1: Load the Raw Multi-Spectral Data

Download and load the numpy array containing all 13 spectral bands for our forest scene.

```bash
!wget -q https://storage.googleapis.com/generativeai-downloads/gemini-cookbook/images/remote-sensing/download_fo_multi_spectral_bands.npy -O download_fo_multi_spectral_bands.npy
```

```python
s2_image = np.load('download_fo_multi_spectral_bands.npy')
print(s2_image.shape)  # Output: (64, 64, 13)
```
The shape `(64, 64, 13)` confirms we have a 64x64 pixel image with 13 different spectral bands.

### Step 2: Understand Band Index Mapping

We need a mapping from Sentinel-2 band names to their indices in the numpy array.

```python
band_name_to_index={
        "B01": 0,
        "B02": 1,
        "B03": 2,
        "B04": 3,
        "B05": 4,
        "B06": 5,
        "B07": 6,
        "B08": 7,
        "B8A": 8,
        "B09": 9,
        "B10": 10,
        "B11": 11,
        "B12": 12,
    }
```

### Step 3: Create an NDVI Composite Image

We'll recreate the NDVI (Normalized Difference Vegetation Index) image. NDVI is calculated using the Red (`B04`) and Near-Infrared (`B08`) bands.

**Formula:** `NDVI = (NIR - Red) / (NIR + Red)`

First, extract the necessary bands.

```python
red_band = s2_image[:, :, band_name_to_index['B04']]
nir_band = s2_image[:, :, band_name_to_index['B08']]
print(red_band.shape, nir_band.shape)  # Output: (64, 64) (64, 64)
```

Now, define a function to calculate NDVI and convert it into a color-mapped RGB image.

```python
def generate_ndvi_image(
    red_band: np.ndarray, nir_band: np.ndarray
) -> np.ndarray:
  """Generate an NDVI image from red and nir bands."""

  # 1. Calculate the NDVI index
  ndvi_image = (nir_band - red_band) / (nir_band + red_band)

  # 2. Apply a color map (Red-Yellow-Green) to the NDVI values
  ndvi_image = plt.get_cmap('RdYlGn')(ndvi_image)

  # 3. Scale values from 0-1 to the standard 0-255 integer range for an RGB image
  ndvi_image = np.uint8(ndvi_image * 255)
  return ndvi_image
```

**How the function works:**
1.  **Calculation:** The `ndvi_image` variable becomes an array of floating-point numbers between -1 and 1, representing vegetation health.
2.  **Color Mapping:** The `'RdYlGn'` colormap transforms these numbers into colors. Low values (water, bare soil) map to red, medium values to yellow, and high values (dense, healthy vegetation) to green.
3.  **Scaling:** The floating-point color values are converted to 8-bit integers (0-255), creating a standard RGB image array.

### Step 4: Generate and Visualize the NDVI Image

Run the function and display the result.

```python
ndvi_image = generate_ndvi_image(red_band, nir_band)
plt.imshow(ndvi_image)
plt.show()
```

You will see a predominantly green image, confirming the area is rich with healthy vegetation—a clear indicator of a forest.

## Summary

You have successfully learned a technique for zero-shot multi-spectral remote sensing with Gemini:

1.  **The Limitation:** Standard RGB satellite imagery can lead to misclassification by generalist vision models.
2.  **The Solution:** Transform key spectral bands (like NIR, SWIR) into composite images (like NDVI, False Color) and provide Gemini with the scientific context for these images.
3.  **The Workflow:** Select bands relevant to your task, calculate the index, apply an appropriate color map, and include a detailed prompt explaining the image's meaning.

By following this process, you can leverage Gemini's powerful visual understanding for specialized remote sensing applications such as monitoring crop health, detecting water bodies, or assessing fire damage—all without any model fine-tuning.