# Building a Vector Database with Redis and OpenAI Embeddings

This guide walks you through using Redis as a high-performance vector database. You'll learn how to index and search vector embeddings generated by OpenAI's API using the RediSearch module. By the end, you'll have a functional system for semantic search and hybrid queries.

## Prerequisites

Before starting, ensure you have:
- A running Redis instance with the RediSearch module (we'll use Redis Stack via Docker).
- An OpenAI API key.
- Python 3.7+ installed.

## Step 1: Start Redis with Docker

We'll use the Redis Stack Docker image, which includes RediSearch and a management GUI.

1.  Create a `docker-compose.yml` file with the following content:

    ```yaml
    version: '3.8'
    services:
      redis-stack:
        image: redis/redis-stack:latest
        container_name: redis-stack
        ports:
          - "6379:6379"
          - "8001:8001"
        volumes:
          - ./data:/data
    ```

2.  Start the container:

    ```bash
    docker-compose up -d
    ```

3.  Verify it's running by accessing the RedisInsight GUI at [http://localhost:8001](http://localhost:8001).

## Step 2: Install Python Dependencies

Install the required Python libraries in your environment.

```bash
pip install redis pandas openai wget
```

## Step 3: Configure Your OpenAI API Key

Your API key is required to generate vector embeddings for queries.

1.  Set the key as an environment variable in your terminal:
    ```bash
    export OPENAI_API_KEY="your-api-key-here"
    ```
    *(Note: If you're running this in a notebook, you may need to restart your kernel for the variable to be recognized.)*

2.  Test the configuration in Python:

    ```python
    import os
    import openai

    if os.getenv("OPENAI_API_KEY") is not None:
        openai.api_key = os.getenv("OPENAI_API_KEY")
        print("OPENAI_API_KEY is ready")
    else:
        print("OPENAI_API_KEY environment variable not found")
    ```

## Step 4: Load the Sample Dataset

We'll use a pre-processed Wikipedia dataset that already contains vector embeddings.

```python
import sys
import os
import pandas as pd

# Add the current directory to the path to import a local helper module
if os.getcwd() not in sys.path:
    sys.path.append(os.getcwd())

# Assuming nbutils.py is in the same directory
import nbutils

# Download and read the data (this may take a few minutes)
nbutils.download_wikipedia_data()
data = nbutils.read_wikipedia_data()

# Inspect the first few rows
print(data.head())
```

The dataset contains columns like `id`, `title`, `url`, `text`, `title_vector`, and `content_vector`. The `*_vector` columns are the pre-computed embeddings.

## Step 5: Connect to Redis

Establish a connection to your local Redis instance.

```python
import redis
from redis.commands.search.indexDefinition import IndexDefinition, IndexType
from redis.commands.search.query import Query
from redis.commands.search.field import TextField, VectorField

REDIS_HOST = "localhost"
REDIS_PORT = 6379
REDIS_PASSWORD = ""  # Default for no password

redis_client = redis.Redis(
    host=REDIS_HOST,
    port=REDIS_PORT,
    password=REDIS_PASSWORD
)

# Test the connection
print("Connection successful!" if redis_client.ping() else "Connection failed.")
```

## Step 6: Create a Search Index

To perform vector searches, you must first define and create an index on your Redis data.

1.  Set constants for the index configuration:

    ```python
    # Constants
    VECTOR_DIM = len(data['title_vector'][0])  # Dimension of the vectors
    VECTOR_NUMBER = len(data)                  # Number of vectors to index
    INDEX_NAME = "embeddings-index"            # Name of the search index
    PREFIX = "doc"                             # Key prefix for stored documents
    DISTANCE_METRIC = "COSINE"                 # Similarity metric (COSINE, IP, L2)
    ```

2.  Define the schema for the index. This tells RediSearch which fields to index and their types.

    ```python
    # Define RediSearch fields
    title = TextField(name="title")
    url = TextField(name="url")
    text = TextField(name="text")
    title_embedding = VectorField("title_vector",
        "FLAT", {
            "TYPE": "FLOAT32",
            "DIM": VECTOR_DIM,
            "DISTANCE_METRIC": DISTANCE_METRIC,
            "INITIAL_CAP": VECTOR_NUMBER,
        }
    )
    text_embedding = VectorField("content_vector",
        "FLAT", {
            "TYPE": "FLOAT32",
            "DIM": VECTOR_DIM,
            "DISTANCE_METRIC": DISTANCE_METRIC,
            "INITIAL_CAP": VECTOR_NUMBER,
        }
    )
    fields = [title, url, text, title_embedding, text_embedding]
    ```

3.  Create the index. The `FLAT` index type is a brute-force index, suitable for smaller datasets or exact searches.

    ```python
    # Check if index exists, create if it doesn't
    try:
        redis_client.ft(INDEX_NAME).info()
        print("Index already exists")
    except:
        redis_client.ft(INDEX_NAME).create_index(
            fields=fields,
            definition=IndexDefinition(prefix=[PREFIX], index_type=IndexType.HASH)
        )
        print(f"Index '{INDEX_NAME}' created.")
    ```

## Step 7: Load Documents into Redis

Now, insert the Wikipedia articles into Redis as Hash objects. We need to convert the vector lists into the byte format Redis expects.

```python
import numpy as np

def index_documents(client: redis.Redis, prefix: str, documents: pd.DataFrame):
    """Convert DataFrame records to Redis Hashes and store them."""
    records = documents.to_dict("records")
    for doc in records:
        key = f"{prefix}:{str(doc['id'])}"

        # Convert vector lists to byte arrays
        title_embedding = np.array(doc["title_vector"], dtype=np.float32).tobytes()
        content_embedding = np.array(doc["content_vector"], dtype=np.float32).tobytes()

        # Replace the list with the byte vector
        doc["title_vector"] = title_embedding
        doc["content_vector"] = content_embedding

        # Store as a Redis Hash
        client.hset(key, mapping=doc)

# Load all documents
index_documents(redis_client, PREFIX, data)
print(f"Loaded {redis_client.info()['db0']['keys']} documents into Redis.")
```

## Step 8: Perform Vector Search Queries

Let's create a reusable function for semantic search. It will:
1.  Generate an embedding for the user's query using OpenAI.
2.  Execute a K-Nearest Neighbors (KNN) search in Redis.
3.  Return the most relevant documents.

```python
def search_redis(
    redis_client: redis.Redis,
    user_query: str,
    index_name: str = "embeddings-index",
    vector_field: str = "title_vector",
    return_fields: list = ["title", "url", "text", "vector_score"],
    hybrid_fields: str = "*",
    k: int = 20,
    print_results: bool = True,
):
    """Perform a vector similarity search in Redis."""

    # 1. Generate embedding for the query
    embedded_query = openai.Embedding.create(
        input=user_query,
        model="text-embedding-3-small",
    )["data"][0]['embedding']

    # 2. Prepare the RediSearch query
    base_query = f'{hybrid_fields}=>[KNN {k} @{vector_field} $vector AS vector_score]'
    query = (
        Query(base_query)
         .return_fields(*return_fields)
         .sort_by("vector_score")
         .paging(0, k)
         .dialect(2)
    )
    params_dict = {"vector": np.array(embedded_query).astype(dtype=np.float32).tobytes()}

    # 3. Execute the search
    results = redis_client.ft(index_name).search(query, params_dict)

    # 4. Print formatted results
    if print_results:
        for i, article in enumerate(results.docs):
            # Convert distance to similarity score (for COSINE)
            score = 1 - float(article.vector_score)
            print(f"{i}. {article.title} (Score: {round(score ,3) })")
    return results.docs
```

### Run Example Searches

Search using the `title_vector` field:

```python
results = search_redis(redis_client, 'modern art in Europe', k=5)
```

Search using the `content_vector` field for deeper semantic matching within article text:

```python
results = search_redis(redis_client,
                       'Famous battles in Scottish history',
                       vector_field='content_vector',
                       k=5)
```

## Step 9: Execute Hybrid Queries

Redis excels at combining vector search with traditional filters, like exact text matching. This is called a hybrid query.

1.  First, create a helper to format filter conditions:

    ```python
    def create_hybrid_field(field_name: str, value: str) -> str:
        """Format a RediSearch filter for exact text match."""
        return f'@{field_name}:"{value}"'
    ```

2.  Run a hybrid query: find articles about "Famous battles in Scottish history" but only those where the title contains "Scottish".

    ```python
    results = search_redis(redis_client,
                           "Famous battles in Scottish history",
                           vector_field="title_vector",
                           k=3,
                           hybrid_fields=create_hybrid_field("title", "Scottish")
                           )
    ```

3.  Run another hybrid query: find articles semantically related to "Art", but filter to only those whose text mentions "Leonardo da Vinci".

    ```python
    results = search_redis(redis_client,
                           "Art",
                           vector_field="title_vector",
                           k=3,
                           hybrid_fields=create_hybrid_field("text", "Leonardo da Vinci")
                           )
    # Extract the specific sentence mentioning Leonardo
    if results:
        mention = [s for s in results[0].text.split("\n") if "Leonardo da Vinci" in s][0]
        print(f"Mention found: {mention}")
    ```

## Step 10: Implement an HNSW Index for Speed

For larger datasets, the `FLAT` index can be slow. The `HNSW` (Hierarchical Navigable Small World) index provides faster approximate search.

1.  Redefine the vector fields to use the `HNSW` index type:

    ```python
    title_embedding_hnsw = VectorField("title_vector",
        "HNSW", {
            "TYPE": "FLOAT32",
            "DIM": VECTOR_DIM,
            "DISTANCE_METRIC": DISTANCE_METRIC,
            "INITIAL_CAP": VECTOR_NUMBER
        }
    )
    text_embedding_hnsw = VectorField("content_vector",
        "HNSW", {
            "TYPE": "FLOAT32",
            "DIM": VECTOR_DIM,
            "DISTANCE_METRIC": DISTANCE_METRIC,
            "INITIAL_CAP": VECTOR_NUMBER
        }
    )
    fields_hnsw = [title, url, text, title_embedding_hnsw, text_embedding_hnsw]
    ```

2.  Create a new index with the HNSW schema. Since documents already exist, RediSearch will index them in the background.

    ```python
    import time
    HNSW_INDEX_NAME = INDEX_NAME + "_HNSW"

    try:
        redis_client.ft(HNSW_INDEX_NAME).info()
        print("HNSW index already exists")
    except:
        redis_client.ft(HNSW_INDEX_NAME).create_index(
            fields=fields_hnsw,
            definition=IndexDefinition(prefix=[PREFIX], index_type=IndexType.HASH)
        )
        print(f"HNSW index '{HNSW_INDEX_NAME}' created.")

    # Optional: Wait for background indexing to complete
    while int(redis_client.ft(HNSW_INDEX_NAME).info().get("indexing", 0)) == 1:
        time.sleep(2)
    print("HNSW indexing is complete.")
    ```

3.  Perform a search using the new HNSW index:

    ```python
    results = search_redis(redis_client,
                           'modern art in Europe',
                           index_name=HNSW_INDEX_NAME,
                           k=5)
    ```

### Compare FLAT vs. HNSW Performance

Let's benchmark the query speed of both index types.

```python
import time

def time_queries(iterations: int = 10):
    print("----- FLAT Index -----")
    t0 = time.time()
    for _ in range(iterations):
        _ = search_redis(redis_client, 'modern art in Europe', k=10, print_results=False)
    avg_time_flat = (time.time() - t0) / iterations
    print(f"Average FLAT query time: {round(avg_time_flat, 3)} seconds\n")

    time.sleep(1)  # Brief pause

    print("----- HNSW Index -----")
    t1 = time.time()
    for _ in range(iterations):
        _ = search_redis(redis_client, 'modern art in Europe', index_name=HNSW_INDEX_NAME, k=10, print_results=False)
    avg_time_hnsw = (time.time() - t1) / iterations
    print(f"Average HNSW query time: {round(avg_time_hnsw, 3)} seconds")
    print("----------------------")

    speedup = avg_time_flat / avg_time_hnsw
    print(f"HNSW is approximately {round(speedup, 1)}x faster for this query.")

time_queries(iterations=5)
```

## Conclusion

You've successfully built a vector search pipeline using Redis and OpenAI. You learned how to:
- Set up Redis with the RediSearch module.
- Create vector search indices (`FLAT` and `HNSW`).
- Load and query vector embeddings.
- Combine vector search with traditional filters for hybrid queries.

This system forms a robust foundation for applications like semantic search, recommendation engines, or Retrieval-Augmented Generation (RAG). For production, consider using a managed Redis service like [Redis Cloud](https://redis.com/try-free/) for scalability and high availability.