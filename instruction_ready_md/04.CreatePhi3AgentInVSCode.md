# Guide: Building a Custom Phi-3 Agent for GitHub Copilot Chat in VS Code

This guide walks you through creating a custom AI agent for GitHub Copilot Chat in Visual Studio Code. You'll build a VS Code extension that integrates a Phi-3 model, allowing you to interact with it directly from the chat interface using custom commands like `/gen` and `/img`.

## Prerequisites

Before you begin, ensure you have the following:

*   **Visual Studio Code Insiders 1.90+**: The Chat Participant API is currently available in the Insiders build.
*   **Node.js and npm**: Required for building the extension.
*   **A Local Phi-3 API Endpoint**: This guide assumes you have a Phi-3 model running locally (e.g., via Ollama or a similar service) at `http://localhost:8080`. You will also need the endpoint details for a Phi-3-Vision model for image-related tasks.
*   **Basic familiarity with TypeScript and VS Code extension development**.

## Step 1: Create the Extension Project

First, set up the basic structure for your VS Code extension.

1.  Open a terminal and navigate to your desired workspace directory.
2.  Run the Yeoman generator to scaffold a new extension project:
    ```bash
    npx --package yo --package generator-code -- yo code
    ```
3.  Follow the interactive prompts. For this project, make the following selections:
    *   **New Extension (TypeScript)**
    *   **Yes** to using Webpack for bundling.

This creates a new folder with all the necessary starter files for your extension.

## Step 2: Add the `vscode.d.ts` Type Definitions

The Chat Participant API is a newer proposal. To use it in TypeScript, you need the corresponding type definitions.

1.  Download the latest `vscode.d.ts` file from the official VS Code repository:
    *   [https://github.com/microsoft/vscode/blob/main/src/vscode-dts/vscode.d.ts](https://github.com/microsoft/vscode/blob/main/src/vscode-dts/vscode.d.ts)
2.  Place the downloaded `vscode.d.ts` file in the root of your extension project folder. This provides your TypeScript compiler with the definitions for the `chatParticipants` API.

## Step 3: Configure the Extension Manifest (`package.json`)

The `package.json` file defines your extension's metadata, dependencies, and how it integrates with VS Code.

Replace the default `package.json` in your project with the following configuration. This defines a chat participant named "PHI3" with two commands and enables the necessary API proposals.

```json
{
  "name": "phi3ext",
  "displayName": "phi3ext",
  "description": "A custom Phi-3 agent for Copilot Chat",
  "version": "0.0.1",
  "engines": {
    "vscode": "^1.90.0"
  },
  "categories": [
    "AI",
    "Chat"
  ],
  "activationEvents": [],
  "enabledApiProposals": [
    "chatVariableResolver"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "chatParticipants": [
      {
        "id": "chat.PHI3",
        "name": "PHI3",
        "description": "Hey! I am PHI3",
        "isSticky": true,
        "commands": [
          {
            "name": "gen",
            "description": "I am PHI3, you can gen code with me"
          },
          {
            "name": "img",
            "description": "I am PHI3-vision, you can gen code from img with me"
          }
        ]
      }
    ],
    "commands": [
      {
        "command": "PHI3.namesInEditor",
        "title": "Use PHI3 in Editor"
      }
    ]
  },
  "scripts": {
    "vscode:prepublish": "npm run package",
    "compile": "webpack",
    "watch": "webpack --watch",
    "package": "webpack --mode production --devtool hidden-source-map",
    "compile-tests": "tsc -p . --outDir out",
    "watch-tests": "tsc -p . -w --outDir out",
    "pretest": "npm run compile-tests && npm run compile && npm run lint",
    "lint": "eslint src --ext ts",
    "test": "vscode-test"
  },
  "devDependencies": {
    "@types/vscode": "^1.90.0",
    "@types/mocha": "^10.0.6",
    "@types/node": "18.x",
    "@typescript-eslint/eslint-plugin": "^7.11.0",
    "@typescript-eslint/parser": "^7.11.0",
    "eslint": "^8.57.0",
    "typescript": "^5.4.5",
    "ts-loader": "^9.5.1",
    "webpack": "^5.91.0",
    "webpack-cli": "^5.1.4",
    "@vscode/test-cli": "^0.0.9",
    "@vscode/test-electron": "^2.4.0"
  },
  "dependencies": {
    "@types/node-fetch": "^2.6.11",
    "node-fetch": "^3.3.2"
  }
}
```

4.  Install the project dependencies by running the following command in your project's terminal:
    ```bash
    npm install
    ```

## Step 4: Implement the Extension Logic (`src/extension.ts`)

Now, you'll write the core logic for your Phi-3 agent. This involves creating a chat request handler that processes user commands and communicates with your Phi-3 model APIs.

Replace the contents of `src/extension.ts` with the following code:

```typescript
import * as vscode from 'vscode';

// Define a custom interface for the chat result that includes command metadata
interface IPHI3ChatResult extends vscode.ChatResult {
    metadata: {
        command: string;
    }
}

// Core activation function for the extension
export function activate(extcontext: vscode.ExtensionContext) {

    // Define the main handler for chat requests to the PHI3 agent
    const phi3handler: vscode.ChatRequestHandler = async (request: vscode.ChatRequest, context: vscode.ChatContext, stream: vscode.ChatResponseStream, token: vscode.CancellationToken): Promise<IPHI3ChatResult> => {

        // Handle the '/gen' command for text-based code generation
        if (request.command == 'gen') {
            const result = await gen(request.prompt);
            // Stream the generated code back to the chat, formatted in a code block
            stream.progress("```txt\n" + result + "\n```");
            return { metadata: { command: 'gen' } };
        }

        // Handle the '/img' command for image-based code generation
        if (request.command == 'img') {
            const prompt = request.prompt;

            // Parse the prompt for an image URL in the format: "Question (IMG_URL:http://...)"
            if (prompt.indexOf("(IMG_URL:") > -1) {
                const img_url = prompt.split("(IMG_URL:")[1].split(")")[0];
                const question = prompt.split("(IMG_URL:")[0];

                const result = await genImage(question, img_url);
                stream.progress(result);
                return { metadata: { command: 'img' } };
            } else {
                // Inform the user of the correct format if the URL is missing
                const errorMsg = "```txt\n\nPlease ask a question like this: 'Your question (IMG_URL:https://example.com/image.jpg)'\n\n```";
                stream.progress(errorMsg);
                return { metadata: { command: 'img' } };
            }
        }

        // Default return if no recognized command is found
        return { metadata: { command: '' } };
    }

    // Create and register the chat participant with VS Code
    const phi3Participant = vscode.chat.createChatParticipant("chat.PHI3", phi3handler);
    phi3Participant.iconPath = new vscode.ThemeIcon('sparkle');

    // Provide a follow-up suggestion after an interaction
    phi3Participant.followupProvider = {
        provideFollowups(result: IPHI3ChatResult, context: vscode.ChatContext, token: vscode.CancellationToken) {
            return [{
                prompt: 'let us code with Phi-3 Family',
                label: vscode.l10n.t('Dev with Phi-3 Family'),
                command: 'help'
            } satisfies vscode.ChatFollowup];
        }
    };

    // Clean up on extension deactivation
    extcontext.subscriptions.push(phi3Participant);
}

// --- Helper functions to call the Phi-3 APIs ---

// Interface for the request to the local text-generation endpoint
interface GenCodeRequest {
    question: string;
}

// Interface for the response from the local text-generation endpoint
interface GenCodeResponse {
    answer: string;
}

// Calls the local Phi-3 endpoint for text-to-code generation
async function gen(prompt: string): Promise<string> {
    const postData: GenCodeRequest = {
        question: prompt
    };
    const response = await fetch('http://localhost:8080/score', {
        method: 'POST',
        body: JSON.stringify(postData),
        headers: { 'Content-Type': 'application/json' }
    });
    const post = await response.json();
    const resultResponse = post as GenCodeResponse;
    return resultResponse.answer;
}

// Interface for the response from the Phi-3-Vision endpoint
interface ImgGenCodeResponse {
    output: string;
}

// Calls a Phi-3-Vision endpoint for image-to-code generation
async function genImage(prompt: string, img_url: string): Promise<string> {
    // IMPORTANT: Replace placeholder values with your actual endpoint details
    const endpointUrl = 'Your Phi-3-Vision Endpoint';
    const apiKey = 'Bearer Your Phi-3-Vision Endpoint Key';
    const deploymentName = 'Your Phi-3-Vision Deployment name';

    const response = await fetch(endpointUrl, {
        method: 'POST',
        body: JSON.stringify({
            "input_data": {
                "input_string": [{
                    "role": "user",
                    "content": [
                        { "type": "text", "text": prompt },
                        { "type": "image_url", "image_url": { "url": img_url } }
                    ]
                }],
                "parameters": {
                    "temperature": 0.6,
                    "top_p": 0.9,
                    "do_sample": false,
                    "max_new_tokens": 2048
                }
            }
        }),
        headers: {
            'Content-Type': 'application/json',
            'Authorization': apiKey,
            'azureml-model-deployment': deploymentName
        }
    });
    const post = await response.json();
    const resultResponse = post as ImgGenCodeResponse;
    return resultResponse.output;
}

// This method is called when your extension is deactivated
export function deactivate() { }
```

**Key Implementation Notes:**

1.  **Local Text Endpoint**: The `gen()` function sends a POST request to `http://localhost:8080/score`. You must have a compatible service running at this address.
2.  **Cloud Vision Endpoint**: The `genImage()` function contains placeholders for a cloud-based Phi-3-Vision endpoint (like Azure AI Foundry). You must replace `'Your Phi-3-Vision Endpoint'`, `'Your Phi-3-Vision Endpoint Key'`, and `'Your Phi-3-Vision Deployment name'` with your actual service credentials.
3.  **Error Handling**: The code includes basic parsing for the `/img` command to ensure the user provides an image URL in the correct format.

## Step 5: Build, Run, and Test

1.  **Build the Extension**: Open the integrated terminal in VS Code (in your extension project) and run the compile script:
    ```bash
    npm run compile
    ```
    This uses Webpack to bundle your TypeScript code into `dist/extension.js`.

2.  **Run the Extension**: Press `F5` or go to the Run view and click "Start Debugging". This will launch a new VS Code Insiders window (the Extension Development Host) with your extension loaded.

3.  **Test Your Agent**:
    *   In the new VS Code window, open the GitHub Copilot Chat panel (View > Command Palette > "Focus on Chat View").
    *   Type `@PHI3 /gen Write a Python function to calculate factorial` and send the message. The agent should process the request through your local endpoint and stream the code response back into the chat.
    *   Type `@PHI3 /img Explain this code (IMG_URL:https://example.com/screenshot.png)` and send the message. The agent will attempt to call your vision endpoint with the provided image URL.

## Conclusion

You have successfully created a custom Phi-3 agent for GitHub Copilot Chat. This extension allows you to leverage both local and cloud-based Phi-3 models directly within your VS Code workflow. You can extend this further by adding more commands, improving error handling, or integrating additional AI services.