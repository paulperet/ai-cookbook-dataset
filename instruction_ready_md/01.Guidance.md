# Guide: Using Guidance-AI with Phi-3.5-mini Models as a Service

This guide walks you through using the **Guidance-AI** framework with the **Phi-3.5-mini** serverless endpoint in Azure AI Foundry. Guidance provides token-by-token control over model outputs, enabling structured, predictable results while reducing cost and latency by 30-50% compared to standard prompting.

## Prerequisites

Before you begin, ensure you have the following:

1.  An **Azure AI Foundry** project.
2.  Access to the **Phi-3.5-mini** model endpoint.
3.  Your Azure AI endpoint URL and API key.

## Setup

First, install the required packages and configure your environment.

```bash
pip install guidance azure-ai-inference
```

Now, import the necessary libraries and set up your Azure AI credentials.

```python
import guidance
import os

# Set your Azure AI endpoint and API key
os.environ["AZURE_AI_ENDPOINT"] = "YOUR_ENDPOINT_URL"
os.environ["AZURE_AI_API_KEY"] = "YOUR_API_KEY"
```

## Step 1: Initialize the Guidance Program with Azure AI

Guidance uses a templating syntax to define the structure of the model's output. We'll start by creating a simple program that uses the Phi-3.5-mini model via the Azure AI backend.

```python
# Define a Guidance program
program = guidance("""
{{#system}}You are a helpful assistant.{{/system}}

{{#user}}
Please provide a short summary of artificial intelligence.
{{/user}}

{{#assistant}}
{{gen 'summary' max_tokens=100}}
{{/assistant}}
""")

# Execute the program using the Azure AI backend
result = program()
print(result["summary"])
```

**Explanation:** This program defines a simple conversation with a system prompt, a user question, and an instruction for the assistant to generate a summary. The `gen` command generates text, constrained here to a maximum of 100 tokens.

## Step 2: Constrain Outputs with Regular Expressions

A key feature of Guidance is the ability to constrain the model's output to match specific patterns, such as selecting from a list or following a regex. This eliminates the need for post-processing and retries.

```python
# Define a program that forces the model to select a valid medical code
program = guidance("""
{{#system}}You are a medical coding assistant. Choose the correct ICD-10 code from the list.{{/system}}

{{#user}}
Patient presents with acute bronchitis. Select the appropriate code.
Options: J20.9, I10, E11.9, M54.5
{{/user}}

{{#assistant}}
The correct ICD-10 code is: {{select 'code' options=options}}
{{/assistant}}
""")

# Execute with the options list provided
result = program(options=["J20.9", "I10", "E11.9", "M54.5"])
print(f"Selected Code: {result['code']}")
```

**Explanation:** The `select` command forces the model to choose its next token from the provided `options` list. This ensures the output is always a valid, pre-defined code, making the response predictable and parseable.

## Step 3: Generate Structured JSON Output

You can use Guidance to generate complex, structured outputs like JSON objects directly, which is invaluable for building APIs or data pipelines.

```python
# Define a program to extract structured information into JSON
program = guidance("""
{{#system}}Extract the following information from the user's message into a JSON object.{{/system}}

{{#user}}
My name is John Doe and my email is john.doe@example.com. I am reporting an issue with login.
{{/user}}

{{#assistant}}
```json
{
    "name": "{{gen 'name'}}",
    "email": "{{gen 'email'}}",
    "issue_type": "{{gen 'issue'}}"
}
```
{{/assistant}}
""")

result = program()
print(result["name"], result["email"], result["issue"])
```

**Explanation:** This program guides the model to generate a valid JSON block. Each `gen` command fills in a specific field. The structure is defined in the prompt, so the model's output conforms to it directly.

## Step 4: Implement Tool Use with a Calculator

Guidance can seamlessly interleave text generation with tool calls. Hereâ€™s an example of using a simple calculator function within a reasoning task.

```python
# First, define a simple calculator tool
def calculator(expression):
    try:
        return eval(expression)
    except:
        return "Error"

# Create a Guidance program that uses the tool
program = guidance("""
{{#system}}You are a math tutor. Solve problems step-by-step and use the calculator when needed.{{/system}}

{{#user}}
What is (15 * 4) + (72 / 8)?
{{/user}}

{{#assistant}}
Let's solve this step by step.
First, calculate 15 * 4.
15 * 4 = {{~calc '15*4'}}
Now, calculate 72 / 8.
72 / 8 = {{~calc '72/8'}}
Finally, add the results: {{calc '15*4'}} + {{calc '72/8'}} = {{~calc '60+9'}}
The final answer is {{gen 'answer'}}.
{{/assistant}}
""")

# Execute the program, providing the 'calc' tool
result = program(calc=calculator)
print(result["answer"])
```

**Explanation:** The `~` prefix before a tool call (`{{~calc}}`) tells Guidance to execute the function and insert its result directly into the prompt before continuing generation. This allows for dynamic, accurate calculations within the narrative.

## Step 5: Deploy for Production

For production deployment, you can wrap your Guidance program in a function and deploy it as an API endpoint within your Azure AI Foundry project.

```python
import guidance
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

# Define a request model
class QueryRequest(BaseModel):
    user_input: str

# Load your pre-defined Guidance program
program = guidance("""
{{#system}}You are a helpful assistant.{{/system}}
{{#user}}{{query}}{{/user}}
{{#assistant}}{{gen 'response' max_tokens=150}}{{/assistant}}
""")

@app.post("/chat/")
async def chat_endpoint(request: QueryRequest):
    result = program(query=request.user_input)
    return {"response": result["response"]}
```

**Next Steps:** You can deploy this FastAPI application using Azure Container Apps or Azure App Service, connecting it to your Phi-3.5-mini endpoint for scalable, cost-effective inference.

## Summary

By following this guide, you've learned how to:
1.  Set up Guidance with the Azure AI Phi-3.5-mini endpoint.
2.  Use `select` and `gen` commands to constrain and structure model outputs.
3.  Generate parseable formats like JSON directly.
4.  Integrate external tools into the generation process.
5.  Structure a simple program for deployment.

Guidance provides precise control over Phi models, enabling you to build reliable, efficient, and cost-effective AI applications. For more advanced patterns and examples, refer to the [Guidance-AI GitHub repository](https://github.com/guidance-ai/guidance).