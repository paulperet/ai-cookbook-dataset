# PDF Summarization with Indexify and Mistral: A Step-by-Step Guide

This guide walks you through building a scalable PDF summarization pipeline using Indexify and Mistral's large language models. You'll create a system capable of ingesting and summarizing thousands of PDF documents.

## Introduction

Our pipeline consists of two core steps:
1.  **Text Extraction:** Convert PDFs to plain text using a pre-built extractor.
2.  **Summarization:** Process the extracted text with Mistral's LLM to generate concise summaries.

## Prerequisites

Before you begin, ensure you have:
*   Python 3.9 or later installed.
*   `pip` (Python's package manager).
*   A valid [Mistral API key](https://console.mistral.ai/).
*   Basic familiarity with Python and the command line.

## Step 1: Environment and Indexify Setup

### 1.1 Create a Virtual Environment
First, create and activate a Python virtual environment to manage dependencies.

```bash
python3.9 -m venv ve
source ve/bin/activate  # On Windows, use `ve\Scripts\activate`
```

### 1.2 Install and Start Indexify
Install the Indexify server using the official script.

```bash
curl https://getindexify.ai | sh
```

Start the Indexify server. The `-d` flag runs it in the background as a long-running service.

```bash
./indexify server -d
```

## Step 2: Install and Configure Extractors

In a **new terminal window**, install the Indexify Extractor SDK and download the specific extractors needed for this pipeline.

```bash
pip install indexify-extractor-sdk
indexify-extractor download tensorlake/pdfextractor
indexify-extractor download tensorlake/mistral
```

Once downloaded, start the extractor server. This process will host the PDF and Mistral extractors.

```bash
indexify-extractor join-server
```

## Step 3: Define the Extraction Graph

The extraction graph defines the data flow for your pipeline. You will create a graph that first extracts text from a PDF and then sends that text to Mistral for summarization.

Create a new Python script (e.g., `create_pipeline.py`) and add the following code.

```python
from indexify import IndexifyClient, ExtractionGraph

# Initialize the client
client = IndexifyClient()

# Define the pipeline using YAML
extraction_graph_spec = """
name: 'pdf_summarizer'
extraction_policies:
  - extractor: 'tensorlake/pdfextractor'
    name: 'pdf_to_text'
  - extractor: 'tensorlake/mistral'
    name: 'text_to_summary'
    input_params:
      model_name: 'mistral-large-latest'
      key: 'YOUR_MISTRAL_API_KEY'  # REPLACE WITH YOUR KEY
      system_prompt: 'Summarize the following text in a concise manner, highlighting the key points:'
    content_source: 'pdf_to_text'
"""

# Create the graph from the YAML specification
extraction_graph = ExtractionGraph.from_yaml(extraction_graph_spec)
client.create_extraction_graph(extraction_graph)

print("‚úÖ Extraction graph 'pdf_summarizer' created successfully.")
```

**Important:** Replace `'YOUR_MISTRAL_API_KEY'` with your actual Mistral API key.

Run the script to create the pipeline:
```bash
python create_pipeline.py
```

## Step 4: Implement the Summarization Function

Now, let's write the core function that uses the pipeline. This function will download a PDF, upload it to Indexify, and retrieve the generated summary.

Create a new script (e.g., `summarize.py`).

```python
import os
import requests
from indexify import IndexifyClient

def download_pdf(url, save_path):
    """Helper function to download a PDF from a URL."""
    response = requests.get(url)
    with open(save_path, 'wb') as f:
        f.write(response.content)
    print(f"üì• PDF downloaded and saved to {save_path}")

def summarize_pdf(pdf_path):
    """Main function to upload a PDF and get its summary."""
    client = IndexifyClient()
    
    # 1. Upload the PDF file to the 'pdf_summarizer' pipeline
    content_id = client.upload_file("pdf_summarizer", pdf_path)
    print(f"üì§ File uploaded. Content ID: {content_id}")
    
    # 2. Wait for the extraction pipeline to complete processing
    print("‚è≥ Waiting for extraction to complete...")
    client.wait_for_extraction(content_id)
    
    # 3. Retrieve the summarized content generated by the 'text_to_summary' policy
    summary = client.get_extracted_content(
        content_id=content_id,
        graph_name="pdf_summarizer",
        policy_name="text_to_summary"
    )
    
    # Decode the summary from bytes to a readable string
    return summary[0]['content'].decode('utf-8')

# Example Usage
if __name__ == "__main__":
    # Specify a PDF URL and local save path
    pdf_url = "https://arxiv.org/pdf/2310.06825.pdf"
    pdf_path = "reference_document.pdf"
    
    # Download the PDF
    download_pdf(pdf_url, pdf_path)
    
    # Get and print the summary
    print("\nüìÑ Summary of the PDF:")
    print("-" * 40)
    summary_text = summarize_pdf(pdf_path)
    print(summary_text)
```

Run the script to test the entire pipeline:
```bash
python summarize.py
```

You should see the download confirmation, upload status, and finally, the AI-generated summary of the PDF printed to your console.

## Step 5: Customize and Experiment

The power of this pipeline lies in its flexibility. You can easily customize the summarization behavior by modifying the `system_prompt` in the extraction graph YAML.

**Examples:**

*   **Bullet-Point Summary:**
    ```yaml
    system_prompt: 'Summarize the following text as a list of concise bullet points:'
    ```
*   **Focus on Arguments:**
    ```yaml
    system_prompt: 'Extract and summarize the main arguments and supporting evidence from the following text:'
    ```
*   **Technical Abstract:**
    ```yaml
    system_prompt: 'Act as a research assistant. Provide a one-paragraph abstract of the following technical paper:'
    ```

You can also experiment with different Mistral models by changing the `model_name` parameter (e.g., `'mistral-medium'`, `'open-mistral-7b'`) to optimize for cost, speed, or quality.

## Conclusion

You have successfully built a production-ready PDF summarization pipeline. While the implementation is straightforward, Indexify provides significant advantages:

1.  **Scalability & High Availability:** The Indexify server can be deployed on cloud infrastructure, enabling it to process thousands of concurrent PDFs. The system includes automatic retries and failover.
2.  **Flexibility:** You can swap the `tensorlake/pdfextractor` for any other [supported PDF extraction method](https://docs.getindexify.ai/usecases/pdf_extraction/) if your documents require specialized handling.

## Next Steps

*   Explore the [Indexify documentation](https://docs.getindexify.ai) to learn about advanced features like persistent vector indexes and complex multi-step graphs.
*   See another practical application: [Entity Extraction from PDF Documents](../pdf-entity-extraction/).
*   Deploy the Indexify server and extractors to a cloud environment for large-scale processing.